---
title: エコシステムアーキテクチャ
description: AI-Protocol、ai-lib-rust、ai-lib-python が統合エコシステムとしてどのように連携するか。
---

# エコシステムアーキテクチャ

AI-Lib エコシステムは、各レイヤーが明確な責務を持つクリーンな 3 層アーキテクチャで構築されています。現在のバージョン：**AI-Protocol v0.5.0**、**ai-lib-rust v0.7.1**、**ai-lib-python v0.6.0**。

## 3 つのレイヤー

### 1. プロトコルレイヤー — AI-Protocol

**仕様**レイヤーです。YAML マニフェストで以下を定義します：

- **プロバイダーマニフェスト**（`providers/*.yaml`）— 30 以上のプロバイダーそれぞれのエンドポイント、認証、パラメータマッピング、ストリーミングデコーダー、エラー分類
- **モデルレジストリ**（`models/*.yaml`）— コンテキストウィンドウ、機能、価格を持つモデルインスタンス
- **コア仕様**（`spec.yaml`）— 標準パラメータ、イベント、エラー型、リトライポリシー
- **スキーマ**（`schemas/`）— すべての設定の JSON Schema 検証

プロトコルレイヤーは**言語非依存**です。あらゆる言語のランタイムから消費されます。

### 2. ランタイムレイヤー — Rust & Python SDK

**実行**レイヤーです。ランタイムは以下を実装します：

- **プロトコル読み込み** — ローカルファイル、環境変数、GitHub からマニフェストを読み取り検証
- **リクエストコンパイル** — 統合リクエストをプロバイダー固有の HTTP 呼び出しに変換
- **ストリーミングパイプライン** — プロバイダーレスポンスをデコード、選択、蓄積、統一イベントにマッピング
- **耐障害性** — サーキットブレーカー、レート制限、リトライ、フォールバック
- **拡張機能** — 埋め込み、キャッシュ、バッチ処理、プラグイン

両ランタイムは同じアーキテクチャを共有します：

| コンセプト | Rust | Python |
|------------|------|--------|
| クライアント | `AiClient` | `AiClient` |
| ビルダー | `AiClientBuilder` | `AiClientBuilder` |
| リクエスト | `ChatRequestBuilder` | `ChatRequestBuilder` |
| イベント | `StreamingEvent` enum | `StreamingEvent` class |
| トランスポート | reqwest (tokio) | httpx (asyncio) |
| 型 | Rust structs | Pydantic v2 models |

### 3. アプリケーションレイヤー — あなたのコード

アプリケーションは統合ランタイム API を使用します。単一の `AiClient` インターフェースがすべてのプロバイダーで動作します：

```
Your App → AiClient → Protocol Manifest → Provider API
```

モデル識別子を 1 つ変更するだけでプロバイダーを切り替えられます。コード変更は不要です。

## データフロー

`client.chat().user("Hello").stream()` を呼び出すと何が起こるか：

1. **AiClient** がリクエストを受け取る
2. **ProtocolLoader** がプロバイダーマニフェストを提供する
3. **リクエストコンパイラ** が標準パラメータをプロバイダー固有の JSON にマッピングする
4. **トランスポート** が正しい認証/ヘッダーで HTTP リクエストを送信する
5. **パイプライン** がストリーミングレスポンスを処理する：
   - **Decoder** がバイト → JSON フレーム（SSE または NDJSON）に変換
   - **Selector** が JSONPath で関連フレームをフィルタリング
   - **Accumulator** が部分的なツール呼び出しを組み立てる
   - **EventMapper** がフレーム → 統一 `StreamingEvent` に変換
6. **アプリケーション** が統一イベントをイテレートする

## プロトコルの読み込み

両ランタイムは次の順序でプロトコルマニフェストを検索します：

1. **カスタムパス** — ビルダーで明示的に設定
2. **環境変数** — `AI_PROTOCOL_DIR` または `AI_PROTOCOL_PATH`
3. **相対パス** — 作業ディレクトリからの `ai-protocol/` または `../ai-protocol/`
4. **GitHub フォールバック** — `hiddenpath/ai-protocol` リポジトリからダウンロード

つまり、ローカルセットアップなしで開発を開始できます。ランタイムが GitHub からマニフェストを自動的に取得します。

## V2 プロトコルの進化

プロトコル v0.5.0 リリースでは **3 層ピラミッド** アーキテクチャを導入しています：

- **L1 コアプロトコル** — メッセージ形式、標準エラーコード（E1001–E9999）、バージョン宣言
- **L2 機能拡張** — ストリーミング、ビジョン、ツール — それぞれフィーチャーフラグで制御
- **L3 環境プロファイル** — API キー、エンドポイント、リトライポリシー — 環境固有の設定

**コンプライアンステストスイート**（42 テストケース、両ランタイムで 20/20 合格）により、Rust と Python 実装間で同一の動作が保証されます。

## MCP との関係

AI-Protocol と MCP（Model Context Protocol）は**補完的**です：

- **MCP** は高レベルの関心事 — ツール登録、コンテキスト管理、エージェント調整
- **AI-Protocol** は低レベルの関心事 — API 正規化、ストリーミング形式変換、エラー分類

これらは異なるレイヤーで動作し、併用できます。

## 次のステップ

- **[AI-Protocol 概要](/protocol/overview/)** — 仕様を詳しく学ぶ
- **[Rust SDK](/rust/overview/)** — Rust ランタイムを探索する
- **[Python SDK](/python/overview/)** — Python ランタイムを探索する
